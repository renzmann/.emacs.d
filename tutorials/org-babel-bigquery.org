#+TITLE:Setting up Org Babel for BigQuery
#+AUTHOR: Robert Enzmann
#+OPTIONS: ^:nil
#+PROPERTY: header-args :exports both
#+PROPERTY: header-args:sql :engine bq

* Org Settings/Options
Disabling the underscore-to-subscript behavior when printing a table that
has underscores in a column name is done with this document-level option:

#+begin_src org
  #+OPTIONS: ^:nil
#+end_src

Then, to ensure table results are exported alongside the query when converting
to HTML or previewing in GitHub, we set this property globally:

#+begin_src org
  #+PROPERTY: header-args :exports both
#+end_src

GitHub can have some trouble picking up on the ~:exports~ though.  In particular,
if a table doesn't have an explicitly underlined header row, it won't render.
In that case, some of the blocks still need their own ~:exports both~ to ensure
the table shows up on the GitHub rich view.

And finally, the ~:engine bq~ property for ~sql~ blocks is what we're going to patch
in this document so that we can get nice ~C-c C-c~ execution.

#+begin_src org
  PROPERTY: header-args:sql :engine bq
#+end_src

* Login and setup
When I need to authenticate to GCP with my single-sign-on (SSO), I use this.

#+begin_src shell
  gcloud auth
#+end_src

Then, set the project in which the tables reside

#+begin_src shell :results none
  gcloud projects list
  # gcloud config set project <id-from-list>
#+end_src

#+begin_src shell
  gcloud datasets
#+end_src

#+RESULTS:

Then, try querying:

#+begin_src shell :results drawer table :exports both
  bq query --format=csv 'SELECT PClass, avg(Survived) AS pct_survived FROM abc_pilot.titanic GROUP BY PClass;'
#+end_src

#+RESULTS:
:results:
| PClass |        pct_survived |
|      3 | 0.24236252545824846 |
|      1 |  0.6296296296296297 |
|      2 | 0.47282608695652173 |
:end:


Both the ~--format=sparse~ and ~--format=csv~ options are handled well when viewing
within Org, but ~--format=json~ is the easiest for the computer to parse, and what
we'll use alongside a special function to convert it into an org table.

* Setting up a Babel Backend
Since I know that the command line version works pretty well, I just hack around
it using a small library called [[https://github.com/noonker/json-to-org-table][json-to-org-table]]:

#+begin_src emacs-lisp :results none
  (defun org-babel-execute:bq (orig-fun body params)
    (if (string-equal-ignore-case (cdr (assq :engine params)) "bq")
        (json-to-org-table-parse-json-string (org-babel-execute:shell (concat "bq query --format=json '" body "'") params))
      (org-babel-execute:sql body params)))

  (advice-add 'org-babel-execute:sql :around #'org-babel-execute:bq)
#+end_src

By advising with =:around=, we capture any call to ~org-babel-execute:sql~, and
check if the =:engine= argument is ="bq"=, ignoring capitalization.  If it is, then
we execute our query through ~org-babel-execute:shell~, which we already saw works
pretty well.  If not, just pass through to the old ~org-babel-execute:sql~.

Additionally, in order to guarantee the GitHub render of our table, we need to
ensure that there's a line under our columns.

Now, we can execute SQL blocks using good old-fashioned ~C-c C-c~.

#+begin_src sql
  SELECT
      PClass,
      ROUND(AVG(Survived), 2) AS pct_survived
  FROM
      abc_pilot.titanic
  GROUP BY
      PClass
  ORDER BY
      PClass;
#+end_src

#+RESULTS:
| PClass | pct_survived |
|--------+--------------|
|      1 |         0.63 |
|      2 |         0.47 |
|      3 |         0.24 |
